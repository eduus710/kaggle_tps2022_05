{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d62c8a4-ce66-4109-b9c1-5072d429f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from warnings import simplefilter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "simplefilter(\"ignore\")\n",
    "input_dir = Path('input')\n",
    "\n",
    "RANDOM_STATE=1967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afec2534-52bd-4fcc-98b9-9ddef7a8b646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>f_09</th>\n",
       "      <th>...</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "      <th>f_26</th>\n",
       "      <th>f_27</th>\n",
       "      <th>f_28</th>\n",
       "      <th>f_29</th>\n",
       "      <th>f_30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.373246</td>\n",
       "      <td>0.238887</td>\n",
       "      <td>-0.243376</td>\n",
       "      <td>0.567405</td>\n",
       "      <td>-0.647715</td>\n",
       "      <td>0.839326</td>\n",
       "      <td>0.113133</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.540739</td>\n",
       "      <td>0.766952</td>\n",
       "      <td>-2.730628</td>\n",
       "      <td>-0.208177</td>\n",
       "      <td>1.363402</td>\n",
       "      <td>ABABDADBAB</td>\n",
       "      <td>67.609153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.697021</td>\n",
       "      <td>-1.710322</td>\n",
       "      <td>-2.230332</td>\n",
       "      <td>-0.545661</td>\n",
       "      <td>1.113173</td>\n",
       "      <td>-1.552175</td>\n",
       "      <td>0.447825</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.278315</td>\n",
       "      <td>-0.633658</td>\n",
       "      <td>-1.217077</td>\n",
       "      <td>-3.782194</td>\n",
       "      <td>-0.058316</td>\n",
       "      <td>ACACCADCEB</td>\n",
       "      <td>377.096415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.681726</td>\n",
       "      <td>0.616746</td>\n",
       "      <td>-1.027689</td>\n",
       "      <td>0.810492</td>\n",
       "      <td>-0.609086</td>\n",
       "      <td>0.113965</td>\n",
       "      <td>-0.708660</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.385775</td>\n",
       "      <td>-0.520558</td>\n",
       "      <td>-0.009121</td>\n",
       "      <td>2.788536</td>\n",
       "      <td>-3.703488</td>\n",
       "      <td>AAAEABCKAD</td>\n",
       "      <td>-195.599702</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118172</td>\n",
       "      <td>-0.587835</td>\n",
       "      <td>-0.804638</td>\n",
       "      <td>2.086822</td>\n",
       "      <td>0.371005</td>\n",
       "      <td>-0.128831</td>\n",
       "      <td>-0.282575</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572594</td>\n",
       "      <td>-1.653213</td>\n",
       "      <td>1.686035</td>\n",
       "      <td>-2.533098</td>\n",
       "      <td>-0.608601</td>\n",
       "      <td>BDBBAACBCB</td>\n",
       "      <td>210.826205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.148481</td>\n",
       "      <td>-0.176567</td>\n",
       "      <td>-0.664871</td>\n",
       "      <td>-1.101343</td>\n",
       "      <td>0.467875</td>\n",
       "      <td>0.500117</td>\n",
       "      <td>0.407515</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.912929</td>\n",
       "      <td>-1.430366</td>\n",
       "      <td>2.127649</td>\n",
       "      <td>-3.306784</td>\n",
       "      <td>4.371371</td>\n",
       "      <td>BDBCBBCHFE</td>\n",
       "      <td>-217.211798</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899995</th>\n",
       "      <td>1.380145</td>\n",
       "      <td>-0.038884</td>\n",
       "      <td>0.597111</td>\n",
       "      <td>0.854560</td>\n",
       "      <td>0.684301</td>\n",
       "      <td>-1.058618</td>\n",
       "      <td>1.310699</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.594744</td>\n",
       "      <td>0.522019</td>\n",
       "      <td>0.833047</td>\n",
       "      <td>2.714125</td>\n",
       "      <td>1.290094</td>\n",
       "      <td>BABBCBBBED</td>\n",
       "      <td>455.033851</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899996</th>\n",
       "      <td>-1.369789</td>\n",
       "      <td>0.044841</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>-0.380529</td>\n",
       "      <td>-0.830815</td>\n",
       "      <td>-1.798458</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.413899</td>\n",
       "      <td>-0.674942</td>\n",
       "      <td>-0.412111</td>\n",
       "      <td>-0.030436</td>\n",
       "      <td>-3.144047</td>\n",
       "      <td>BBBGBBDQBE</td>\n",
       "      <td>134.703577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899997</th>\n",
       "      <td>1.386201</td>\n",
       "      <td>-0.961150</td>\n",
       "      <td>0.725994</td>\n",
       "      <td>-0.132844</td>\n",
       "      <td>0.873911</td>\n",
       "      <td>-0.245339</td>\n",
       "      <td>-1.045786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151930</td>\n",
       "      <td>-4.560773</td>\n",
       "      <td>-1.249154</td>\n",
       "      <td>1.793535</td>\n",
       "      <td>2.253696</td>\n",
       "      <td>AEBEDBBHBA</td>\n",
       "      <td>-99.536313</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899998</th>\n",
       "      <td>-1.590572</td>\n",
       "      <td>-0.509938</td>\n",
       "      <td>-1.715397</td>\n",
       "      <td>-0.249988</td>\n",
       "      <td>1.359933</td>\n",
       "      <td>1.650808</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.423670</td>\n",
       "      <td>2.110008</td>\n",
       "      <td>0.561271</td>\n",
       "      <td>-2.149610</td>\n",
       "      <td>1.019982</td>\n",
       "      <td>ADBAAADDAE</td>\n",
       "      <td>47.823039</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899999</th>\n",
       "      <td>-0.636210</td>\n",
       "      <td>-0.425986</td>\n",
       "      <td>-1.826699</td>\n",
       "      <td>-0.598797</td>\n",
       "      <td>1.589577</td>\n",
       "      <td>-0.482298</td>\n",
       "      <td>-0.214093</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340696</td>\n",
       "      <td>3.762351</td>\n",
       "      <td>1.797137</td>\n",
       "      <td>-0.412837</td>\n",
       "      <td>2.090440</td>\n",
       "      <td>BCAACADSCE</td>\n",
       "      <td>-44.559296</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
       "id                                                                             \n",
       "0      -1.373246  0.238887 -0.243376  0.567405 -0.647715  0.839326  0.113133   \n",
       "1       1.697021 -1.710322 -2.230332 -0.545661  1.113173 -1.552175  0.447825   \n",
       "2       1.681726  0.616746 -1.027689  0.810492 -0.609086  0.113965 -0.708660   \n",
       "3      -0.118172 -0.587835 -0.804638  2.086822  0.371005 -0.128831 -0.282575   \n",
       "4       1.148481 -0.176567 -0.664871 -1.101343  0.467875  0.500117  0.407515   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "899995  1.380145 -0.038884  0.597111  0.854560  0.684301 -1.058618  1.310699   \n",
       "899996 -1.369789  0.044841  0.015458  0.376565 -0.380529 -0.830815 -1.798458   \n",
       "899997  1.386201 -0.961150  0.725994 -0.132844  0.873911 -0.245339 -1.045786   \n",
       "899998 -1.590572 -0.509938 -1.715397 -0.249988  1.359933  1.650808 -0.058592   \n",
       "899999 -0.636210 -0.425986 -1.826699 -0.598797  1.589577 -0.482298 -0.214093   \n",
       "\n",
       "        f_07  f_08  f_09  ...      f_22      f_23      f_24      f_25  \\\n",
       "id                        ...                                           \n",
       "0          1     5     1  ... -2.540739  0.766952 -2.730628 -0.208177   \n",
       "1          1     3     4  ...  2.278315 -0.633658 -1.217077 -3.782194   \n",
       "2          1     0     2  ... -1.385775 -0.520558 -0.009121  2.788536   \n",
       "3          3     2     1  ...  0.572594 -1.653213  1.686035 -2.533098   \n",
       "4          3     3     0  ... -3.912929 -1.430366  2.127649 -3.306784   \n",
       "...      ...   ...   ...  ...       ...       ...       ...       ...   \n",
       "899995     2     1     2  ... -1.594744  0.522019  0.833047  2.714125   \n",
       "899996     4     1     2  ...  2.413899 -0.674942 -0.412111 -0.030436   \n",
       "899997     0     0     6  ... -0.151930 -4.560773 -1.249154  1.793535   \n",
       "899998     0     2     2  ...  2.423670  2.110008  0.561271 -2.149610   \n",
       "899999     7     1     4  ...  1.340696  3.762351  1.797137 -0.412837   \n",
       "\n",
       "            f_26        f_27        f_28  f_29  f_30  target  \n",
       "id                                                            \n",
       "0       1.363402  ABABDADBAB   67.609153     0     0       0  \n",
       "1      -0.058316  ACACCADCEB  377.096415     0     0       1  \n",
       "2      -3.703488  AAAEABCKAD -195.599702     0     2       1  \n",
       "3      -0.608601  BDBBAACBCB  210.826205     0     0       1  \n",
       "4       4.371371  BDBCBBCHFE -217.211798     0     1       1  \n",
       "...          ...         ...         ...   ...   ...     ...  \n",
       "899995  1.290094  BABBCBBBED  455.033851     0     2       1  \n",
       "899996 -3.144047  BBBGBBDQBE  134.703577     0     1       0  \n",
       "899997  2.253696  AEBEDBBHBA  -99.536313     0     1       0  \n",
       "899998  1.019982  ADBAAADDAE   47.823039     1     2       0  \n",
       "899999  2.090440  BCAACADSCE  -44.559296     0     2       1  \n",
       "\n",
       "[900000 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(input_dir / 'train.csv')\n",
    "train = train.set_index('id').sort_index()\n",
    "test = pd.read_csv(input_dir / 'test.csv')\n",
    "test = test.set_index('id').sort_index()\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8df0c2-9ba0-494f-8fb2-4fdf78c5a25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_07      16\n",
       "f_08      16\n",
       "f_09      15\n",
       "f_10      15\n",
       "f_11      14\n",
       "f_12      16\n",
       "f_13      13\n",
       "f_14      14\n",
       "f_15      15\n",
       "f_16      16\n",
       "f_17      14\n",
       "f_18      14\n",
       "f_29       2\n",
       "f_30       3\n",
       "target     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(['int64']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c49c6f-1f6e-4223-9fb8-c740fcb58e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_19</th>\n",
       "      <th>f_20</th>\n",
       "      <th>f_21</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "      <th>f_26</th>\n",
       "      <th>f_28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.373246</td>\n",
       "      <td>0.238887</td>\n",
       "      <td>-0.243376</td>\n",
       "      <td>0.567405</td>\n",
       "      <td>-0.647715</td>\n",
       "      <td>0.839326</td>\n",
       "      <td>0.113133</td>\n",
       "      <td>0.298218</td>\n",
       "      <td>-0.919717</td>\n",
       "      <td>3.058541</td>\n",
       "      <td>-2.540739</td>\n",
       "      <td>0.766952</td>\n",
       "      <td>-2.730628</td>\n",
       "      <td>-0.208177</td>\n",
       "      <td>1.363402</td>\n",
       "      <td>67.609153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.697021</td>\n",
       "      <td>-1.710322</td>\n",
       "      <td>-2.230332</td>\n",
       "      <td>-0.545661</td>\n",
       "      <td>1.113173</td>\n",
       "      <td>-1.552175</td>\n",
       "      <td>0.447825</td>\n",
       "      <td>-3.147667</td>\n",
       "      <td>-1.075434</td>\n",
       "      <td>2.179050</td>\n",
       "      <td>2.278315</td>\n",
       "      <td>-0.633658</td>\n",
       "      <td>-1.217077</td>\n",
       "      <td>-3.782194</td>\n",
       "      <td>-0.058316</td>\n",
       "      <td>377.096415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.681726</td>\n",
       "      <td>0.616746</td>\n",
       "      <td>-1.027689</td>\n",
       "      <td>0.810492</td>\n",
       "      <td>-0.609086</td>\n",
       "      <td>0.113965</td>\n",
       "      <td>-0.708660</td>\n",
       "      <td>2.820733</td>\n",
       "      <td>-3.485342</td>\n",
       "      <td>-0.784235</td>\n",
       "      <td>-1.385775</td>\n",
       "      <td>-0.520558</td>\n",
       "      <td>-0.009121</td>\n",
       "      <td>2.788536</td>\n",
       "      <td>-3.703488</td>\n",
       "      <td>-195.599702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118172</td>\n",
       "      <td>-0.587835</td>\n",
       "      <td>-0.804638</td>\n",
       "      <td>2.086822</td>\n",
       "      <td>0.371005</td>\n",
       "      <td>-0.128831</td>\n",
       "      <td>-0.282575</td>\n",
       "      <td>1.081084</td>\n",
       "      <td>-2.100177</td>\n",
       "      <td>-2.343819</td>\n",
       "      <td>0.572594</td>\n",
       "      <td>-1.653213</td>\n",
       "      <td>1.686035</td>\n",
       "      <td>-2.533098</td>\n",
       "      <td>-0.608601</td>\n",
       "      <td>210.826205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.148481</td>\n",
       "      <td>-0.176567</td>\n",
       "      <td>-0.664871</td>\n",
       "      <td>-1.101343</td>\n",
       "      <td>0.467875</td>\n",
       "      <td>0.500117</td>\n",
       "      <td>0.407515</td>\n",
       "      <td>-0.126179</td>\n",
       "      <td>0.605033</td>\n",
       "      <td>1.133665</td>\n",
       "      <td>-3.912929</td>\n",
       "      <td>-1.430366</td>\n",
       "      <td>2.127649</td>\n",
       "      <td>-3.306784</td>\n",
       "      <td>4.371371</td>\n",
       "      <td>-217.211798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899995</th>\n",
       "      <td>1.380145</td>\n",
       "      <td>-0.038884</td>\n",
       "      <td>0.597111</td>\n",
       "      <td>0.854560</td>\n",
       "      <td>0.684301</td>\n",
       "      <td>-1.058618</td>\n",
       "      <td>1.310699</td>\n",
       "      <td>-4.061370</td>\n",
       "      <td>-2.643652</td>\n",
       "      <td>-2.173853</td>\n",
       "      <td>-1.594744</td>\n",
       "      <td>0.522019</td>\n",
       "      <td>0.833047</td>\n",
       "      <td>2.714125</td>\n",
       "      <td>1.290094</td>\n",
       "      <td>455.033851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899996</th>\n",
       "      <td>-1.369789</td>\n",
       "      <td>0.044841</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>-0.380529</td>\n",
       "      <td>-0.830815</td>\n",
       "      <td>-1.798458</td>\n",
       "      <td>-1.721978</td>\n",
       "      <td>0.741793</td>\n",
       "      <td>-5.190605</td>\n",
       "      <td>2.413899</td>\n",
       "      <td>-0.674942</td>\n",
       "      <td>-0.412111</td>\n",
       "      <td>-0.030436</td>\n",
       "      <td>-3.144047</td>\n",
       "      <td>134.703577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899997</th>\n",
       "      <td>1.386201</td>\n",
       "      <td>-0.961150</td>\n",
       "      <td>0.725994</td>\n",
       "      <td>-0.132844</td>\n",
       "      <td>0.873911</td>\n",
       "      <td>-0.245339</td>\n",
       "      <td>-1.045786</td>\n",
       "      <td>-1.265819</td>\n",
       "      <td>1.230005</td>\n",
       "      <td>-1.361833</td>\n",
       "      <td>-0.151930</td>\n",
       "      <td>-4.560773</td>\n",
       "      <td>-1.249154</td>\n",
       "      <td>1.793535</td>\n",
       "      <td>2.253696</td>\n",
       "      <td>-99.536313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899998</th>\n",
       "      <td>-1.590572</td>\n",
       "      <td>-0.509938</td>\n",
       "      <td>-1.715397</td>\n",
       "      <td>-0.249988</td>\n",
       "      <td>1.359933</td>\n",
       "      <td>1.650808</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>1.035249</td>\n",
       "      <td>2.450813</td>\n",
       "      <td>-2.577817</td>\n",
       "      <td>2.423670</td>\n",
       "      <td>2.110008</td>\n",
       "      <td>0.561271</td>\n",
       "      <td>-2.149610</td>\n",
       "      <td>1.019982</td>\n",
       "      <td>47.823039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899999</th>\n",
       "      <td>-0.636210</td>\n",
       "      <td>-0.425986</td>\n",
       "      <td>-1.826699</td>\n",
       "      <td>-0.598797</td>\n",
       "      <td>1.589577</td>\n",
       "      <td>-0.482298</td>\n",
       "      <td>-0.214093</td>\n",
       "      <td>3.472124</td>\n",
       "      <td>1.158922</td>\n",
       "      <td>-0.612109</td>\n",
       "      <td>1.340696</td>\n",
       "      <td>3.762351</td>\n",
       "      <td>1.797137</td>\n",
       "      <td>-0.412837</td>\n",
       "      <td>2.090440</td>\n",
       "      <td>-44.559296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
       "id                                                                             \n",
       "0      -1.373246  0.238887 -0.243376  0.567405 -0.647715  0.839326  0.113133   \n",
       "1       1.697021 -1.710322 -2.230332 -0.545661  1.113173 -1.552175  0.447825   \n",
       "2       1.681726  0.616746 -1.027689  0.810492 -0.609086  0.113965 -0.708660   \n",
       "3      -0.118172 -0.587835 -0.804638  2.086822  0.371005 -0.128831 -0.282575   \n",
       "4       1.148481 -0.176567 -0.664871 -1.101343  0.467875  0.500117  0.407515   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "899995  1.380145 -0.038884  0.597111  0.854560  0.684301 -1.058618  1.310699   \n",
       "899996 -1.369789  0.044841  0.015458  0.376565 -0.380529 -0.830815 -1.798458   \n",
       "899997  1.386201 -0.961150  0.725994 -0.132844  0.873911 -0.245339 -1.045786   \n",
       "899998 -1.590572 -0.509938 -1.715397 -0.249988  1.359933  1.650808 -0.058592   \n",
       "899999 -0.636210 -0.425986 -1.826699 -0.598797  1.589577 -0.482298 -0.214093   \n",
       "\n",
       "            f_19      f_20      f_21      f_22      f_23      f_24      f_25  \\\n",
       "id                                                                             \n",
       "0       0.298218 -0.919717  3.058541 -2.540739  0.766952 -2.730628 -0.208177   \n",
       "1      -3.147667 -1.075434  2.179050  2.278315 -0.633658 -1.217077 -3.782194   \n",
       "2       2.820733 -3.485342 -0.784235 -1.385775 -0.520558 -0.009121  2.788536   \n",
       "3       1.081084 -2.100177 -2.343819  0.572594 -1.653213  1.686035 -2.533098   \n",
       "4      -0.126179  0.605033  1.133665 -3.912929 -1.430366  2.127649 -3.306784   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "899995 -4.061370 -2.643652 -2.173853 -1.594744  0.522019  0.833047  2.714125   \n",
       "899996 -1.721978  0.741793 -5.190605  2.413899 -0.674942 -0.412111 -0.030436   \n",
       "899997 -1.265819  1.230005 -1.361833 -0.151930 -4.560773 -1.249154  1.793535   \n",
       "899998  1.035249  2.450813 -2.577817  2.423670  2.110008  0.561271 -2.149610   \n",
       "899999  3.472124  1.158922 -0.612109  1.340696  3.762351  1.797137 -0.412837   \n",
       "\n",
       "            f_26        f_28  \n",
       "id                            \n",
       "0       1.363402   67.609153  \n",
       "1      -0.058316  377.096415  \n",
       "2      -3.703488 -195.599702  \n",
       "3      -0.608601  210.826205  \n",
       "4       4.371371 -217.211798  \n",
       "...          ...         ...  \n",
       "899995  1.290094  455.033851  \n",
       "899996 -3.144047  134.703577  \n",
       "899997  2.253696  -99.536313  \n",
       "899998  1.019982   47.823039  \n",
       "899999  2.090440  -44.559296  \n",
       "\n",
       "[900000 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(['float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "704496e7-eef8-4df8-ba6e-529ab02b6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(X_in):\n",
    "\n",
    "    X = X_in.select_dtypes(['float64','int64'])\n",
    "    for i in range(10):\n",
    "        X[f\"f_27_{i}\"] = X_in[\"f_27\"].str[i].apply(ord) - ord(\"A\")\n",
    "    X[\"f_27_count\"] =  X_in[\"f_27\"].apply(lambda s: len(set(s)))\n",
    "    \n",
    "#    X[\"f_26_f_00_gt\"] = (X.f_00 + X.f_26 > 5.0).astype('int')\n",
    "#    X[\"f_26_f_00_lt\"] = (X.f_00 + X.f_26 < -5.2).astype('int')\n",
    "    \n",
    "#    X[\"f_21_f_02_gt\"] = (X.f_02 + X.f_21 > 5.2).astype('int')\n",
    "#    X[\"f_21_f_02_lt\"] = (X.f_02 + X.f_21 < -5.3).astype('int')\n",
    "    \n",
    "#    X[\"f_26_f_00_f_01_gt\"] = (X.f_01 + X.f_00 + X.f_26 > 5.0).astype('int')\n",
    "#    X[\"f_26_f_00_f_01_lt\"] = (X.f_01 + X.f_00 + X.f_26 < -5.0).astype('int')\n",
    "\n",
    "#    X[\"f_22_f_05_gt\"] =( X.f_22 + X.f_05 > 5.0).astype('int')\n",
    "#    X[\"f_22_f_05_lt\"] =( X.f_22 + X.f_05 < -5.1).astype('int')\n",
    "\n",
    "    X[\"f_26_f_00\"] = X.f_00 + X.f_26 \n",
    "    X[\"f_21_f_02\"] = X.f_02 + X.f_21 \n",
    "    X[\"f_26_f_00_f_01\"] = X.f_01 + X.f_00 + X.f_26\n",
    "    X[\"f_22_f_05\"] = X.f_22 + X.f_05\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc756b60-ce04-4d28-b6cf-e59d398d7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fit_model(x_train, y_train):\n",
    "\n",
    "    # define the model\n",
    "    model = XGBClassifier(n_estimators=5000, objective='binary:logistic',\n",
    "                          learning_rate=0.09,\n",
    "                      #eval_metric='auc', \n",
    "                      random_state=RANDOM_STATE,\n",
    "                      tree_method='gpu_hist')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0ff033e-5d7c-4a01-8bf0-e2ee09f34317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), make_column_selector(dtype_include=\"float64\")),     \n",
    "#        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), make_column_selector(dtype_include=\"float64\")),     \n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"f_30\"]),\n",
    "    ],\n",
    "    remainder = 'passthrough'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba89d8db-e9af-4cec-b11b-a105daf747f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:25:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:26:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9651933333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y = train.target\n",
    "X = make_features(train.drop(columns=['target']))\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=5000, \n",
    "                    objective='binary:logistic',\n",
    "                    learning_rate=0.10,\n",
    "                    #eval_metric='auc', \n",
    "                    random_state=RANDOM_STATE,\n",
    "                    tree_method='gpu_hist')\n",
    "clf = Pipeline([('transformer', transformer), ('estimator', xgb)])\n",
    "scores = cross_val_score(clf, X, y, cv = 2)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b970cb-b044-4277-9c42-d4aaa60a8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "for p1 in [5.0]:\n",
    "    for p2 in [-5.0]:\n",
    "        print(f\"p1:{p1} p2:{p2}\")\n",
    "        y = train.target\n",
    "        X = make_features(train.drop(columns=['target']), p1, p2)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y)\n",
    "        model = fit_model(X_train, y_train)\n",
    "        y_probs = model.predict_proba(X_test)\n",
    "        auc = roc_auc_score(y_test, y_probs[:,1])\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,y_probs[:,1])\n",
    "        print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e101333-b38a-48f5-8819-c8d4ad0dba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, label=f'AUC (XGBoost) = {auc:.3f}')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56a992-7164-4316-b143-ee6d090bc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_shap = X.sample(3000, random_state=RANDOM_STATE)\n",
    "shap_explainer = shap.TreeExplainer(model)\n",
    "shap_values = shap_explainer.shap_values(X_shap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20336c38-7e56-4c66-a5c8-48c79112cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377d646-f162-426c-abee-c84cbb7b28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_shap, max_display=30, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5d429-0d6b-4a72-b94d-c7f8d5c96750",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values = shap.TreeExplainer(model).shap_interaction_values(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcf9e2-0cac-4821-85fb-891d3ac20ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_interaction_values, X_shap, max_display=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c689a9-e915-4139-9a16-b9ab32d50a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('f_27_count', shap_values, X_shap, x_jitter=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed6af6-64f8-4e51-a0fe-662eff40786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='f_19', y='f_25', hue='target', data=train, alpha=0.2)\n",
    "#plt.plot([-2,2],[-2.5,-7.5], linewidth=2)\n",
    "#plt.plot([-2,2],[7.5,2.5], linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b565d-d979-442d-b6ea-14699e3a54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y='f_26_f_00_f_01', x='f_27_count', hue='target', data=train, alpha=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e406e701-d29c-4288-a7cf-c27993aac667",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y='f_26', x='f_27_count', hue='target', data=train, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea30b6f-9f94-4eef-bd08-c96d62f6ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y='f_01', x='f_27_count', hue='target', data=train, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da195850-ee83-48f3-b420-0ac116ae5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y='f_00', x='f_27_count', hue='target', data=train, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ee7a09e-d426-42b8-b851-5243d143f7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=0, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.085, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=8000, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = make_features(train.drop(columns=['target']))\n",
    "y = train.target\n",
    "model = XGBClassifier(n_estimators=8000, objective='binary:logistic', \n",
    "                      # eval_metric='auc', \n",
    "                      learning_rate=.085,\n",
    "                      tree_method='gpu_hist')\n",
    "\n",
    "#[8000, 6, 1, 0.08566051840702422, 1e-06, 1.0, 1e-06]\n",
    "\n",
    "model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7767198-6426-4bc0-a3e4-a8e8c0075492",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit = make_features(test)\n",
    "submit_probs = model.predict_proba(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd24461b-d8cd-46d0-a70d-298a1a757950",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(submit_probs, columns=['prob_0','target'],index=X_submit.index)\n",
    "submit['target'].to_csv('./ts_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a20186-9d13-474b-af60-08cbc17fe299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_features(train.drop(columns=['target']))\n",
    "y = train.target\n",
    "model = XGBClassifier(objective='binary:logistic', \n",
    "                      # eval_metric='auc', \n",
    "                      tree_method='gpu_hist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "023e6730-747f-40a5-9027-2e01a4157096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "space  = [Integer(5000,10000, name='n_estimators'),\n",
    "          Integer(3,7, name='max_depth'),\n",
    "#          Integer(1,50, name='min_child_weight'),\n",
    "          Real(10**-6, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "#          Real(10**-6, 10**0, \"log-uniform\", name='reg_alpha'),\n",
    "#          Real(10**-6, 10**0, \"log-uniform\", name='reg_lambda'),\n",
    "#          Real(10**-6, 10**0, \"log-uniform\", name='gamma')]\n",
    "\n",
    "#          Integer(2, 100, name='min_samples_split'),\n",
    "#          Integer(1, 100, name='min_samples_leaf')\n",
    "         ]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    model.set_params(**params)\n",
    "    return 1-np.mean(cross_val_score(model, X, y, cv=3, scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc6ea47a-5c79-40b5-bc02-5b1af65509e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[17:11:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:12:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 245.8832\n",
      "Function value obtained: 0.0048\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[17:15:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:18:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:21:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 543.0065\n",
      "Function value obtained: 0.0281\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[17:24:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 228.6282\n",
      "Function value obtained: 0.0687\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[17:28:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:30:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:33:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 489.2224\n",
      "Function value obtained: 0.2649\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[17:36:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:37:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:38:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 171.7435\n",
      "Function value obtained: 0.0100\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[17:39:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:40:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 250.8916\n",
      "Function value obtained: 0.3281\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[17:43:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:45:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:47:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 390.2599\n",
      "Function value obtained: 0.0054\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[17:49:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:52:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:55:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 520.1003\n",
      "Function value obtained: 0.3295\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[17:58:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:01:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:05:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 610.6780\n",
      "Function value obtained: 0.0092\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[18:08:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 270.4401\n",
      "Function value obtained: 0.2128\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "[18:13:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:16:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 535.9331\n",
      "Function value obtained: 0.0066\n",
      "Current minimum: 0.0048\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "[18:22:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:26:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 724.5245\n",
      "Function value obtained: 0.0045\n",
      "Current minimum: 0.0045\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "[18:34:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:34:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 140.2385\n",
      "Function value obtained: 0.0090\n",
      "Current minimum: 0.0045\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "[18:36:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 514.3865\n",
      "Function value obtained: 0.0090\n",
      "Current minimum: 0.0045\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "[18:45:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:45:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:46:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 135.2717\n",
      "Function value obtained: 0.0068\n",
      "Current minimum: 0.0045\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "[18:47:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:56:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 830.3630\n",
      "Function value obtained: 0.0043\n",
      "Current minimum: 0.0043\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "[19:01:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:06:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:11:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 952.5534\n",
      "Function value obtained: 0.0048\n",
      "Current minimum: 0.0043\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "[19:16:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:22:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 464.4706\n",
      "Function value obtained: 0.0044\n",
      "Current minimum: 0.0043\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "[19:24:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:27:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 262.6203\n",
      "Function value obtained: 0.0074\n",
      "Current minimum: 0.0043\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "[19:29:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:31:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:33:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 365.2153\n",
      "Function value obtained: 0.0051\n",
      "Current minimum: 0.0043\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "[19:35:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:40:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 1026.2711\n",
      "Function value obtained: 0.0096\n",
      "Current minimum: 0.0043\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "[19:52:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:54:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:57:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 467.6193\n",
      "Function value obtained: 0.0057\n",
      "Current minimum: 0.0043\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "[20:00:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:10:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gp_minimize\n\u001b[1;32m----> 2\u001b[0m res_gp \u001b[38;5;241m=\u001b[39m \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANDOM_STATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\skopt\\optimizer\\gp.py:259\u001b[0m, in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m, space\u001b[38;5;241m=\u001b[39mspace, random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[0;32m    257\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise)\n\u001b[1;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\skopt\\optimizer\\base.py:299\u001b[0m, in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[0;32m    298\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[1;32m--> 299\u001b[0m     next_y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     result \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtell(next_x, next_y)\n\u001b[0;32m    301\u001b[0m     result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\skopt\\utils.py:789\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    786\u001b[0m arg_dict \u001b[38;5;241m=\u001b[39m {dim\u001b[38;5;241m.\u001b[39mname: value \u001b[38;5;28;01mfor\u001b[39;00m dim, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dimensions, x)}\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m objective_value \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marg_dict)\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objective_value\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(**params)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@use_named_args\u001b[39m(space)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m     19\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroc_auc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost\\core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    505\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost\\sklearn.py:1250\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1230\u001b[0m model, feval, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[0;32m   1231\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1232\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1233\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     label_transform\u001b[38;5;241m=\u001b[39mlabel_transform,\n\u001b[0;32m   1248\u001b[0m )\n\u001b[1;32m-> 1250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost\\training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost\\training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\xgboost\\core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1680\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=50, random_state=RANDOM_STATE, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afb0cc66-a554-48aa-9a15-9a13e2517b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          fun: 0.004359921151885104\n",
       "    func_vals: array([0.35828617, 0.00545829, 0.33145203, 0.00479813, 0.00735749,\n",
       "       0.00642732, 0.14983288, 0.19808355, 0.32506719, 0.32523776,\n",
       "       0.01875699, 0.01257092, 0.00924232, 0.0062651 , 0.0082888 ,\n",
       "       0.03454518, 0.00606608, 0.00960894, 0.00581543, 0.00730827,\n",
       "       0.00503309, 0.00574164, 0.01619682, 0.00587888, 0.00451827,\n",
       "       0.00782988, 0.00440279, 0.00445509, 0.02645025, 0.00682202,\n",
       "       0.00464   , 0.00810481, 0.00643608, 0.00519193, 0.03232538,\n",
       "       0.03483085, 0.00669169, 0.00635883, 0.00875314, 0.01274686,\n",
       "       0.01205822, 0.00639094, 0.00551351, 0.00435992, 0.00591708,\n",
       "       0.00635238, 0.00778024, 0.05704611, 0.00884541, 0.01212429])\n",
       "       models: [GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247)]\n",
       " random_state: RandomState(MT19937) at 0x2799B02BE40\n",
       "        space: Space([Integer(low=4000, high=8000, prior='uniform', transform='normalize'),\n",
       "       Integer(low=3, high=6, prior='uniform', transform='normalize'),\n",
       "       Integer(low=1, high=50, prior='uniform', transform='normalize'),\n",
       "       Real(low=1e-06, high=1, prior='log-uniform', transform='normalize'),\n",
       "       Real(low=1e-06, high=1, prior='log-uniform', transform='normalize'),\n",
       "       Real(low=1e-06, high=1, prior='log-uniform', transform='normalize'),\n",
       "       Real(low=1e-06, high=1, prior='log-uniform', transform='normalize')])\n",
       "        specs: {'args': {'func': <function objective at 0x000002799DA16EE0>, 'dimensions': Space([Integer(low=4000, high=8000, prior='uniform', transform='normalize'),\n",
       "       Integer(low=3, high=6, prior='uniform', transform='normalize'),\n",
       "       Integer(low=1, high=50, prior='uniform', transform='normalize'),\n",
       "       Real(low=1e-06, high=1, prior='log-uniform', transform='normalize'),\n",
       "       Real(low=1e-06, high=1, prior='log-uniform', transform='normalize'),\n",
       "       Real(low=1e-06, high=1, prior='log-uniform', transform='normalize'),\n",
       "       Real(low=1e-06, high=1, prior='log-uniform', transform='normalize')]), 'base_estimator': GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1, 1], nu=2.5),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, random_state=966881247), 'n_calls': 50, 'n_random_starts': None, 'n_initial_points': 10, 'initial_point_generator': 'random', 'acq_func': 'gp_hedge', 'acq_optimizer': 'auto', 'x0': None, 'y0': None, 'random_state': RandomState(MT19937) at 0x2799B02BE40, 'verbose': True, 'callback': None, 'n_points': 10000, 'n_restarts_optimizer': 5, 'xi': 0.01, 'kappa': 1.96, 'n_jobs': 1, 'model_queue_size': None}, 'function': 'base_minimize'}\n",
       "            x: [8000, 6, 1, 0.08566051840702422, 1e-06, 1.0, 1e-06]\n",
       "      x_iters: [[4277, 5, 43, 1.6211582431958138e-06, 0.19063824457796535, 0.0008018972799218707, 8.154951539243357e-05], [4616, 4, 4, 0.205408041129951, 5.2207516754416815e-05, 1.1252220651288516e-06, 3.550094881877828e-05], [6950, 4, 21, 4.71859136362698e-05, 0.033696736118645994, 0.0004094986635081303, 0.02667474177613352], [7022, 5, 4, 0.08755247232029961, 0.11788168707501732, 0.004684444904762866, 0.00011326473624252787], [5521, 4, 2, 0.03951072269925174, 0.0005137239532882433, 4.601854408263217e-06, 2.6697316953152516e-06], [4513, 5, 2, 0.129472225642123, 0.00011530110507827129, 8.758459777548881e-05, 0.7065151858163098], [7321, 4, 36, 0.0001881688208002648, 0.001674480709284637, 0.013588680744632691, 0.20904589777564625], [6917, 3, 38, 0.00018730058277804213, 1.8011213962633497e-05, 0.0009386096969680308, 2.115149717064908e-05], [6605, 6, 29, 7.149275403149022e-06, 0.0008898137708136074, 0.25376710662696833, 2.23617991763278e-06], [6178, 6, 38, 4.5740781705015496e-06, 0.0010701101651838445, 4.9805332807279336e-05, 0.34219711692009636], [8000, 6, 50, 0.0014964907539159748, 1.0, 1.0, 1.0], [8000, 3, 24, 0.10330186761789054, 1.0, 1.0, 1.0], [8000, 3, 50, 1.0, 1.0, 1.0, 1e-06], [4000, 6, 1, 0.020460136493214525, 1e-06, 4.790695090695727e-06, 1e-06], [4000, 6, 1, 1.0, 1.0, 1e-06, 1.0], [8000, 3, 50, 0.004953050567766928, 1.0, 1.0, 1e-06], [8000, 6, 50, 0.34873996388266254, 1.0, 0.05058933995615853, 1e-06], [4000, 6, 1, 0.009672300002372148, 1e-06, 1e-06, 1.0], [4000, 6, 1, 0.3824640618228093, 1e-06, 1.0, 1.0], [4000, 6, 49, 0.0280722291573174, 1e-06, 0.009052495731021034, 1.0], [4000, 6, 50, 0.10925721881610047, 1e-06, 1e-06, 1e-06], [4000, 6, 1, 0.6410525512143416, 1e-06, 1e-06, 1e-06], [4115, 6, 1, 0.003635994968503879, 1e-06, 1e-06, 1.0], [8000, 6, 1, 0.23994488941017855, 1.0, 1e-06, 1.0], [4000, 6, 1, 0.05777085389674292, 1e-06, 1e-06, 0.0324437544596401], [6596, 3, 45, 0.5915439632193036, 1.0, 1e-06, 0.007025164655896931], [4000, 6, 1, 0.15948902262080072, 1.0, 1.0, 0.0010581168729043352], [8000, 6, 1, 0.13427783707441934, 1e-06, 1e-06, 0.000506622805675132], [4000, 3, 1, 0.018208485574100073, 1.0, 1e-06, 0.012175913903683727], [8000, 4, 1, 0.8758973391658248, 1e-06, 1.0, 1e-06], [8000, 6, 21, 0.04500382103573019, 1.0, 1.0, 1e-06], [8000, 5, 1, 0.011811464061440563, 1e-06, 1.0, 1e-06], [4000, 5, 1, 0.03543344927949291, 1.0, 1e-06, 1e-06], [4000, 5, 1, 0.4360939081283476, 1.0, 1.0, 1e-06], [4283, 5, 1, 0.0016570374548169537, 1e-06, 1.0, 3.418413452198699e-06], [8000, 6, 1, 0.0005368483174663079, 1e-06, 1e-06, 1e-06], [8000, 3, 1, 0.3370095330715632, 1e-06, 1.0, 1e-06], [7713, 4, 34, 0.40026388761665405, 7.474404929824153e-06, 0.966740365548557, 0.045248296368172], [5376, 5, 46, 0.9902110801742344, 2.0168331637857517e-05, 6.843337978619253e-06, 0.05169908859599854], [7605, 5, 40, 0.006086495067621011, 0.03508785418814571, 2.161779941973054e-06, 0.0033776804926163436], [4638, 6, 43, 0.005909851140953537, 0.04834768495511502, 0.6271912758877313, 1.7701493590193155e-06], [4235, 4, 8, 0.07320768071185514, 0.00014371279025256138, 0.024623994531161836, 2.059444627597032e-06], [6701, 5, 46, 0.05326216342914709, 2.6015488342393295e-06, 0.24550534401823326, 2.080891684919391e-06], [8000, 6, 1, 0.08566051840702422, 1e-06, 1.0, 1e-06], [7946, 6, 42, 0.016028406976565206, 0.013883847252520136, 0.00010500132245763733, 0.34583922232027053], [7685, 6, 3, 0.6656791157264909, 0.8711132772777018, 0.2805522345394871, 0.4386920471696594], [4087, 3, 49, 0.26547711235614424, 0.051790220741967645, 0.48049996853486526, 1.0419456379464598e-06], [7655, 3, 39, 0.0015660090213004438, 0.7045665141190488, 9.660622158547499e-06, 0.2507597603218001], [4536, 3, 16, 0.8058245049375672, 1.2780326841119096e-06, 1.9126963663084558e-05, 0.7291162196407994], [5583, 3, 45, 0.04905555705645325, 2.397184171728185e-05, 1.8496951701533875e-05, 2.824907996524257e-06]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cd9d002-7c68-48d9-90ee-dc9806381e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004359921151885104"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gp.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e8fbfc0-5f90-48e7-b1af-b46aaf30460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8000, 6, 1, 0.08566051840702422, 1e-06, 1.0, 1e-06]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gp.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a54814-d94f-4f9f-94e8-9e6254e07e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = train[train.f_00 + train.f_26 < 0]\n",
    "y = X.target\n",
    "X = X[['f_00','f_26']]\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85f95ec5-a154-44d0-8175-d04a736da849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2174c50f6d0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = train.target\n",
    "X = train[['f_00','f_26', 'target']]\n",
    "X = X[X.f_00 + X.f_26 < 0]\n",
    "\n",
    "sns.scatterplot(x='f_26', y='f_00', hue='target', data=X, alpha=0.2)\n",
    "\n",
    "xmin, xmax = -5, 5\n",
    "ymin, ymax = -15, 5\n",
    "xd = np.array([xmin, xmax])\n",
    "yd = m*xd + c\n",
    "\n",
    "plt.plot(xd, yd, 'k', lw=1, ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5a26043-59bd-4079-b0ef-81f3c1c0405a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177988</th>\n",
       "      <td>0.183487</td>\n",
       "      <td>-1.684593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798316</th>\n",
       "      <td>0.245360</td>\n",
       "      <td>-0.905040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767994</th>\n",
       "      <td>0.179705</td>\n",
       "      <td>-1.422137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897436</th>\n",
       "      <td>-0.181849</td>\n",
       "      <td>-1.428819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740490</th>\n",
       "      <td>-0.429296</td>\n",
       "      <td>-0.542626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529886</th>\n",
       "      <td>-0.409497</td>\n",
       "      <td>-2.475531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730217</th>\n",
       "      <td>-1.913933</td>\n",
       "      <td>-5.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246970</th>\n",
       "      <td>0.782472</td>\n",
       "      <td>-1.022231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507228</th>\n",
       "      <td>0.822050</td>\n",
       "      <td>-1.224322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834089</th>\n",
       "      <td>0.353582</td>\n",
       "      <td>-3.489157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39589 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_00      f_26\n",
       "id                        \n",
       "177988  0.183487 -1.684593\n",
       "798316  0.245360 -0.905040\n",
       "767994  0.179705 -1.422137\n",
       "897436 -0.181849 -1.428819\n",
       "740490 -0.429296 -0.542626\n",
       "...          ...       ...\n",
       "529886 -0.409497 -2.475531\n",
       "730217 -1.913933 -5.021383\n",
       "246970  0.782472 -1.022231\n",
       "507228  0.822050 -1.224322\n",
       "834089  0.353582 -3.489157\n",
       "\n",
       "[39589 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "177988    0\n",
       "798316    1\n",
       "767994    1\n",
       "897436    0\n",
       "740490    1\n",
       "         ..\n",
       "529886    1\n",
       "730217    1\n",
       "246970    1\n",
       "507228    0\n",
       "834089    0\n",
       "Name: target, Length: 39589, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = train[(train.f_00 + train.f_26) < 0].sample(frac=0.1)\n",
    "y = X.target\n",
    "X = X[['f_00','f_26']]\n",
    "\n",
    "display(X)\n",
    "display(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4220cb83-c2c4-4bc7-8467-08af368d4135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "#clf = make_pipeline(StandardScaler(), reg)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2f302ac-9217-4573-8ce9-e52e51704eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.52467187]), array([-2.13351826]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = clf.intercept_[0]\n",
    "w1, w2 = clf.coef_.T\n",
    "# Calculate the intercept and gradient of the decision boundary.\n",
    "c = -b/w2\n",
    "m = -w1/w2\n",
    "c, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bab3d03-5e3e-4bfa-af02-90991c713ecf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() got multiple values for argument 's'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfill_between(xd, yd, ymin, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtab:blue\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfill_between(xd, yd, ymax, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtab:orange\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[38;5;241m*\u001b[39mX[y\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim(xmin, xmax)\n",
      "\u001b[1;31mTypeError\u001b[0m: scatter() got multiple values for argument 's'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data and the classification with the decision boundary.\n",
    "xmin, xmax = -5, 5\n",
    "ymin, ymax = -15, 5\n",
    "xd = np.array([xmin, xmax])\n",
    "yd = m*xd + c\n",
    "\n",
    "plt.plot(xd, yd, 'k', lw=1, ls='--')\n",
    "plt.fill_between(xd, yd, ymin, color='tab:blue', alpha=0.2)\n",
    "plt.fill_between(xd, yd, ymax, color='tab:orange', alpha=0.2)\n",
    "\n",
    "plt.scatter(*X[y==0].T, s=8, alpha=0.5)\n",
    "plt.scatter(*X[y==1].T, s=8, alpha=0.5)\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.xlabel(r'$x_1$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1b485a4-24dd-4665-bab0-35bb793db722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel=\"linear\")\n",
    "#clf = make_pipeline(StandardScaler(), reg)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa94a6cb-ae34-456f-8ff9-c813b81ad958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.53172906e-04, 1.04897671e-05]]), array([-0.99973107]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bd1d17d-33f8-4d43-befb-a4309e2829f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49830d74-5282-4e40-944d-bf39fa5bb261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.60212645640283"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a0d4a87-6c65-463c-98c7-17226af1b4da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DecisionBoundaryDisplay' from 'sklearn.inspection' (C:\\Users\\orovi\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\inspection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionBoundaryDisplay\n\u001b[0;32m      3\u001b[0m disp \u001b[38;5;241m=\u001b[39m DecisionBoundaryDisplay\u001b[38;5;241m.\u001b[39mfrom_estimator(\n\u001b[0;32m      4\u001b[0m      clf, X, response_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m      alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m      6\u001b[0m  )\n\u001b[0;32m      7\u001b[0m disp\u001b[38;5;241m.\u001b[39max_\u001b[38;5;241m.\u001b[39mscatter(X[:, \u001b[38;5;241m0\u001b[39m], X[:, \u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39my, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DecisionBoundaryDisplay' from 'sklearn.inspection' (C:\\Users\\orovi\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\inspection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "     clf, X, response_method=\"predict\",\n",
    "     alpha=0.5,\n",
    " )\n",
    "disp.ax_.scatter(X[:, 0], X[:, 1], c=y, edgecolor=\"k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784f019-4184-45de-b12e-661d358546e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
